"""
æ–‡æœ¬å¤„ç†å·¥å…·æ¨¡å—
ç”¨äºå¤„ç†HTMLåˆ°çº¯æ–‡æœ¬çš„è½¬æ¢å’Œå…¶ä»–æ–‡æœ¬ç›¸å…³æ“ä½œ

ä¸ºä»€ä¹ˆéœ€è¦è¿™ä¸ªæ¨¡å—ï¼Ÿ
- TipTapç¼–è¾‘å™¨è¾“å‡ºHTMLæ ¼å¼å†…å®¹
- AIæœåŠ¡åªæ¥å—çº¯æ–‡æœ¬è¾“å…¥
- éœ€è¦ä¿æŒæ–‡æ¡£çš„é€»è¾‘ç»“æ„ï¼ˆæ®µè½ã€æ¢è¡Œç­‰ï¼‰
"""

from bs4 import BeautifulSoup
import re
import logging
import json
from typing import Optional, Dict, Any

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)


def html_to_plain_text(html_content: str) -> str:
    """
    å°†HTMLå†…å®¹è½¬æ¢ä¸ºAIå¯å¤„ç†çš„çº¯æ–‡æœ¬
    
    è½¬æ¢è¿‡ç¨‹ï¼š
    1. ä½¿ç”¨BeautifulSoupè§£æHTMLç»“æ„
    2. ä¿ç•™æ®µè½ç»“æ„ï¼ˆ<p>æ ‡ç­¾è½¬æ¢ä¸ºæ¢è¡Œï¼‰
    3. ç§»é™¤æ‰€æœ‰HTMLæ ‡ç­¾
    4. æ¸…ç†å¤šä½™çš„ç©ºç™½å­—ç¬¦
    
    Args:
        html_content (str): æ¥è‡ªTipTapç¼–è¾‘å™¨çš„HTMLå†…å®¹
        
    Returns:
        str: æ¸…ç†åçš„çº¯æ–‡æœ¬ï¼Œä¿æŒé€»è¾‘ç»“æ„
        
    Example:
        è¾“å…¥: "<p>ç¬¬ä¸€æ®µå†…å®¹</p><p>ç¬¬äºŒæ®µå†…å®¹</p>"
        è¾“å‡º: "ç¬¬ä¸€æ®µå†…å®¹\n\nç¬¬äºŒæ®µå†…å®¹"
    """
    if not html_content or not html_content.strip():
        return ""
    
    try:
        # ä½¿ç”¨BeautifulSoupè§£æHTML
        # html.parseræ˜¯Pythonå†…ç½®è§£æå™¨ï¼Œé€Ÿåº¦å¿«ä¸”ç¨³å®š
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # ç‰¹æ®Šå¤„ç†ï¼šå°†æ®µè½æ ‡ç­¾è½¬æ¢ä¸ºåŒæ¢è¡Œç¬¦
        # è¿™æ ·å¯ä»¥ä¿æŒä¸“åˆ©æ–‡æ¡£çš„æ®µè½ç»“æ„
        for p_tag in soup.find_all('p'):
            p_tag.insert_after('\n\n')
        
        # å¤„ç†å…¶ä»–å—çº§å…ƒç´ ï¼ˆdiv, h1-h6ç­‰ï¼‰
        for block_tag in soup.find_all(['div', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6']):
            block_tag.insert_after('\n')
        
        # å¤„ç†åˆ—è¡¨é¡¹
        for li_tag in soup.find_all('li'):
            li_tag.insert_before('- ')  # æ·»åŠ åˆ—è¡¨æ ‡è®°
            li_tag.insert_after('\n')
        
        # è·å–çº¯æ–‡æœ¬å†…å®¹
        text = soup.get_text()
        
        # æ¸…ç†æ–‡æœ¬ï¼š
        # 1. ç§»é™¤HTMLå®ä½“ï¼ˆ&nbsp; ç­‰ï¼‰
        text = re.sub(r'&[a-zA-Z]+;', ' ', text)
        
        # 2. ç»Ÿä¸€æ¢è¡Œç¬¦ï¼ˆWindows/Mac/Linuxå…¼å®¹ï¼‰
        text = re.sub(r'\r\n|\r', '\n', text)
        
        # 3. æ¸…ç†å¤šä½™çš„ç©ºç™½å­—ç¬¦
        # å°†å¤šä¸ªè¿ç»­çš„ç©ºæ ¼æ›¿æ¢ä¸ºå•ä¸ªç©ºæ ¼
        text = re.sub(r'[ \t]+', ' ', text)
        
        # 4. æ¸…ç†å¤šä½™çš„æ¢è¡Œç¬¦
        # æœ€å¤šä¿ç•™ä¸¤ä¸ªè¿ç»­æ¢è¡Œç¬¦ï¼ˆæ®µè½åˆ†éš”ï¼‰
        text = re.sub(r'\n\s*\n\s*\n+', '\n\n', text)
        
        # 5. ç§»é™¤é¦–å°¾ç©ºç™½
        text = text.strip()
        
        logger.info(f"HTMLè½¬æ¢å®Œæˆï¼š{len(html_content)} -> {len(text)} å­—ç¬¦")
        return text
        
    except Exception as e:
        logger.error(f"HTMLè½¬çº¯æ–‡æœ¬å¤±è´¥: {e}")
        # é™çº§å¤„ç†ï¼šç®€å•ç§»é™¤HTMLæ ‡ç­¾
        return re.sub(r'<[^>]+>', '', html_content).strip()


def validate_text_for_ai(text: str) -> tuple[bool, str]:
    """
    éªŒè¯æ–‡æœ¬æ˜¯å¦é€‚åˆAIå¤„ç†
    
    æ£€æŸ¥é¡¹ç›®ï¼š
    1. æ–‡æœ¬é•¿åº¦æ˜¯å¦åˆç†
    2. æ˜¯å¦åŒ…å«HTMLæ ‡ç­¾ï¼ˆè½¬æ¢å¤±è´¥çš„æ ‡å¿—ï¼‰
    3. æ˜¯å¦ä¸ºç©ºæˆ–åªæœ‰ç©ºç™½å­—ç¬¦
    
    Args:
        text (str): å¾…éªŒè¯çš„çº¯æ–‡æœ¬
        
    Returns:
        tuple[bool, str]: (æ˜¯å¦æœ‰æ•ˆ, é”™è¯¯ä¿¡æ¯)
    """
    if not text or not text.strip():
        return False, "æ–‡æœ¬ä¸ºç©º"
    
    # æ£€æŸ¥æ˜¯å¦ä»åŒ…å«HTMLæ ‡ç­¾
    if re.search(r'<[^>]+>', text):
        return False, "æ–‡æœ¬ä»åŒ…å«HTMLæ ‡ç­¾ï¼Œè½¬æ¢å¯èƒ½å¤±è´¥"
    
    # æ£€æŸ¥æ–‡æœ¬é•¿åº¦ï¼ˆAIæœ‰tokené™åˆ¶ï¼‰
    if len(text) > 10000:  # çº¦4000ä¸ªtokençš„é™åˆ¶
        return False, f"æ–‡æœ¬è¿‡é•¿({len(text)}å­—ç¬¦)ï¼Œå¯èƒ½è¶…å‡ºAIå¤„ç†é™åˆ¶"
    
    if len(text) < 10:
        return False, "æ–‡æœ¬è¿‡çŸ­ï¼Œå¯èƒ½ä¸æ˜¯æœ‰æ•ˆçš„ä¸“åˆ©å†…å®¹"
    
    return True, "æ–‡æœ¬æœ‰æ•ˆ"


def extract_claims_section(text: str) -> str:
    """
    ä»ä¸“åˆ©æ–‡æ¡£ä¸­æå–Claimséƒ¨åˆ†
    
    AIæç¤ºè¯ä¸“é—¨é’ˆå¯¹ä¸“åˆ©Claimséƒ¨åˆ†è¿›è¡Œåˆ†æï¼Œ
    å› æ­¤æˆ‘ä»¬åªéœ€è¦å‘é€Claimséƒ¨åˆ†ç»™AI
    
    Args:
        text (str): å®Œæ•´çš„ä¸“åˆ©æ–‡æ¡£æ–‡æœ¬
        
    Returns:
        str: Claimséƒ¨åˆ†çš„æ–‡æœ¬ï¼Œå¦‚æœæ‰¾ä¸åˆ°åˆ™è¿”å›å…¨æ–‡
    """
    # æŸ¥æ‰¾Claimsç« èŠ‚çš„å¼€å§‹
    claims_patterns = [
        r'(?i)claims?\s*:?\s*\n',  # "Claims:" or "Claim:"
        r'(?i)ä»€ä¹ˆæ˜¯å£°æ˜\s*:?\s*\n',  # ä¸­æ–‡
        r'(?i)æƒåˆ©è¦æ±‚\s*:?\s*\n',   # ä¸­æ–‡ä¸“åˆ©æœ¯è¯­
    ]
    
    for pattern in claims_patterns:
        match = re.search(pattern, text)
        if match:
            # ä»Claimså¼€å§‹åˆ°æ–‡æ¡£ç»“å°¾
            claims_text = text[match.start():]
            logger.info(f"æ‰¾åˆ°Claimséƒ¨åˆ†ï¼Œé•¿åº¦: {len(claims_text)}")
            return claims_text
    
    # å¦‚æœæ‰¾ä¸åˆ°Claimséƒ¨åˆ†ï¼Œè¿”å›å…¨æ–‡
    logger.warning("æœªæ‰¾åˆ°Claimséƒ¨åˆ†ï¼Œä½¿ç”¨å…¨æ–‡")
    return text


# æµ‹è¯•å‡½æ•°
def test_html_conversion():
    """
    æµ‹è¯•HTMLè½¬æ¢åŠŸèƒ½çš„ç®€å•æµ‹è¯•å‡½æ•°
    """
    test_cases = [
        # ç®€å•æ®µè½
        ("<p>è¿™æ˜¯ç¬¬ä¸€æ®µ</p><p>è¿™æ˜¯ç¬¬äºŒæ®µ</p>", "è¿™æ˜¯ç¬¬ä¸€æ®µ\n\nè¿™æ˜¯ç¬¬äºŒæ®µ"),
        
        # åŒ…å«åˆ—è¡¨
        ("<ul><li>ç¬¬ä¸€é¡¹</li><li>ç¬¬äºŒé¡¹</li></ul>", "- ç¬¬ä¸€é¡¹\n- ç¬¬äºŒé¡¹"),
        
        # å¤æ‚HTML
        ("<div><h1>æ ‡é¢˜</h1><p>å†…å®¹<strong>åŠ ç²—</strong>éƒ¨åˆ†</p></div>", "æ ‡é¢˜\nå†…å®¹åŠ ç²—éƒ¨åˆ†"),
    ]
    
    print("ğŸ§ª æµ‹è¯•HTMLè½¬æ¢åŠŸèƒ½...")
    for i, (html_input, expected) in enumerate(test_cases, 1):
        result = html_to_plain_text(html_input)
        success = result.strip() == expected.strip()
        print(f"æµ‹è¯• {i}: {'âœ…' if success else 'âŒ'}")
        if not success:
            print(f"  æœŸæœ›: {repr(expected)}")
            print(f"  å®é™…: {repr(result)}")


class StreamingJSONParser:
    """
    æµå¼JSONè§£æå™¨
    
    ä¸ºä»€ä¹ˆéœ€è¦è¿™ä¸ªç±»ï¼Ÿ
    - AIæœåŠ¡è¿”å›æµå¼å“åº”ï¼ŒJSONæ•°æ®åˆ†å¤šä¸ªå—å‘é€
    - éœ€è¦ç¼“å­˜ä¸å®Œæ•´çš„JSONæ•°æ®ç›´åˆ°æ¥æ”¶å®Œæ•´
    - å¤„ç†AIå“åº”ä¸­å¯èƒ½å‡ºç°çš„æ ¼å¼é”™è¯¯
    
    ä½¿ç”¨ç¤ºä¾‹:
        parser = StreamingJSONParser()
        for chunk in ai_stream:
            result = parser.add_chunk(chunk)
            if result:
                # å¤„ç†å®Œæ•´çš„JSONå¯¹è±¡
                handle_ai_suggestion(result)
    """
    
    def __init__(self):
        """åˆå§‹åŒ–è§£æå™¨"""
        self.buffer = ""  # ç¼“å­˜æœªå®Œæˆçš„JSONæ•°æ®
        self.reset_count = 0  # é‡ç½®è®¡æ•°å™¨ï¼Œç”¨äºè°ƒè¯•
    
    def add_chunk(self, chunk: str) -> Optional[Dict[Any, Any]]:
        """
        æ·»åŠ æ–°çš„JSONæ•°æ®å—å¹¶å°è¯•è§£æ
        
        Args:
            chunk (str): æ¥è‡ªAIçš„JSONæ•°æ®å—
            
        Returns:
            Optional[Dict]: è§£ææˆåŠŸè¿”å›JSONå¯¹è±¡ï¼Œå¦åˆ™è¿”å›None
        """
        if not chunk:
            return None
        
        # å°†æ–°å—æ·»åŠ åˆ°ç¼“å†²åŒº
        self.buffer += chunk
        
        # å°è¯•å¤šç§æ–¹å¼è§£æJSON
        return self._try_parse_json()
    
    def _try_parse_json(self) -> Optional[Dict[Any, Any]]:
        """
        å°è¯•è§£æç¼“å†²åŒºä¸­çš„JSONæ•°æ®
        
        å¤„ç†ç­–ç•¥ï¼š
        1. ç›´æ¥è§£æå®Œæ•´JSON
        2. æ¸…ç†å¸¸è§çš„æ ¼å¼é—®é¢˜
        3. æŸ¥æ‰¾å¹¶æå–å¯èƒ½çš„JSONå¯¹è±¡
        """
        if not self.buffer.strip():
            return None
        
        # ç­–ç•¥1: ç›´æ¥è§£æ
        try:
            result = json.loads(self.buffer)
            self.buffer = ""  # æˆåŠŸåæ¸…ç©ºç¼“å†²åŒº
            logger.info("JSONè§£ææˆåŠŸï¼ˆç›´æ¥è§£æï¼‰")
            return result
        except json.JSONDecodeError:
            pass
        
        # ç­–ç•¥2: æ¸…ç†å¸¸è§é—®é¢˜åè§£æ
        cleaned_buffer = self._clean_json_buffer()
        if cleaned_buffer != self.buffer:
            try:
                result = json.loads(cleaned_buffer)
                self.buffer = ""
                logger.info("JSONè§£ææˆåŠŸï¼ˆæ¸…ç†åè§£æï¼‰")
                return result
            except json.JSONDecodeError:
                pass
        
        # ç­–ç•¥3: æŸ¥æ‰¾å¯èƒ½çš„å®Œæ•´JSONå¯¹è±¡
        json_obj = self._extract_json_object()
        if json_obj:
            try:
                result = json.loads(json_obj)
                # ä»ç¼“å†²åŒºç§»é™¤å·²è§£æçš„éƒ¨åˆ†
                self.buffer = self.buffer[self.buffer.find(json_obj) + len(json_obj):]
                logger.info("JSONè§£ææˆåŠŸï¼ˆæå–å¯¹è±¡ï¼‰")
                return result
            except json.JSONDecodeError:
                pass
        
        # å¦‚æœç¼“å†²åŒºè¿‡å¤§ï¼Œé‡ç½®é˜²æ­¢å†…å­˜é—®é¢˜
        if len(self.buffer) > 10000:
            logger.warning(f"ç¼“å†²åŒºè¿‡å¤§({len(self.buffer)})ï¼Œé‡ç½®è§£æå™¨")
            self.reset()
        
        return None
    
    def _clean_json_buffer(self) -> str:
        """
        æ¸…ç†JSONç¼“å†²åŒºä¸­çš„å¸¸è§é—®é¢˜
        
        å¸¸è§é—®é¢˜ï¼š
        - å¤šä½™çš„æ¢è¡Œç¬¦å’Œç©ºæ ¼
        - AIæ·»åŠ çš„å‰ç¼€æ–‡å­—
        - ä¸å®Œæ•´çš„è½¬ä¹‰å­—ç¬¦
        """
        cleaned = self.buffer
        
        # ç§»é™¤é¦–å°¾ç©ºç™½
        cleaned = cleaned.strip()
        
        # ç§»é™¤å¯èƒ½çš„AIå‰ç¼€ï¼ˆå¦‚ "Here's the analysis:" ç­‰ï¼‰
        # æŸ¥æ‰¾ç¬¬ä¸€ä¸ª { å­—ç¬¦ï¼Œä»é‚£é‡Œå¼€å§‹
        first_brace = cleaned.find('{')
        if first_brace > 0:
            cleaned = cleaned[first_brace:]
        
        # ç»Ÿä¸€æ¢è¡Œç¬¦
        cleaned = re.sub(r'\r\n|\r', '\n', cleaned)
        
        # ç§»é™¤JSONä¸­çš„å¤šä½™ç©ºç™½ï¼ˆä½†ä¿ç•™å­—ç¬¦ä¸²å†…çš„ç©ºç™½ï¼‰
        # è¿™ä¸ªæ¯”è¾ƒå¤æ‚ï¼Œå…ˆç®€å•å¤„ç†
        cleaned = re.sub(r'\n\s*', '\n', cleaned)
        
        return cleaned
    
    def _extract_json_object(self) -> Optional[str]:
        """
        ä»ç¼“å†²åŒºä¸­æå–å¯èƒ½çš„å®Œæ•´JSONå¯¹è±¡
        
        ä½¿ç”¨æ‹¬å·è®¡æ•°æ³•æ‰¾åˆ°å®Œæ•´çš„JSONå¯¹è±¡è¾¹ç•Œ
        """
        cleaned = self._clean_json_buffer()
        
        # æŸ¥æ‰¾ç¬¬ä¸€ä¸ª { å­—ç¬¦
        start = cleaned.find('{')
        if start == -1:
            return None
        
        # ä½¿ç”¨æ‹¬å·è®¡æ•°æ‰¾åˆ°åŒ¹é…çš„ }
        brace_count = 0
        in_string = False
        escape_next = False
        
        for i, char in enumerate(cleaned[start:], start):
            if escape_next:
                escape_next = False
                continue
                
            if char == '\\':
                escape_next = True
                continue
                
            if char == '"' and not escape_next:
                in_string = not in_string
                continue
                
            if not in_string:
                if char == '{':
                    brace_count += 1
                elif char == '}':
                    brace_count -= 1
                    
                    # æ‰¾åˆ°åŒ¹é…çš„ç»“æŸæ‹¬å·
                    if brace_count == 0:
                        return cleaned[start:i+1]
        
        return None
    
    def reset(self):
        """é‡ç½®è§£æå™¨çŠ¶æ€"""
        self.buffer = ""
        self.reset_count += 1
        logger.info(f"JSONè§£æå™¨å·²é‡ç½® (ç¬¬{self.reset_count}æ¬¡)")
    
    def get_buffer_info(self) -> str:
        """è·å–ç¼“å†²åŒºä¿¡æ¯ï¼Œç”¨äºè°ƒè¯•"""
        return f"ç¼“å†²åŒºé•¿åº¦: {len(self.buffer)}, é‡ç½®æ¬¡æ•°: {self.reset_count}"


def test_streaming_json_parser():
    """
    æµ‹è¯•æµå¼JSONè§£æå™¨
    """
    print("\nğŸ§ª æµ‹è¯•æµå¼JSONè§£æå™¨...")
    parser = StreamingJSONParser()
    
    # æµ‹è¯•ç”¨ä¾‹1: åˆ†å—å‘é€å®Œæ•´JSON
    chunks = ['{"issues":', ' [{"type":', ' "grammar",', ' "severity": "high"}]}']
    print("æµ‹è¯•1: åˆ†å—JSONè§£æ")
    
    result = None
    for i, chunk in enumerate(chunks):
        print(f"  æ·»åŠ å— {i+1}: {chunk}")
        result = parser.add_chunk(chunk)
        if result:
            print(f"  âœ… è§£ææˆåŠŸ: {result}")
            break
    
    if not result:
        print("  âŒ è§£æå¤±è´¥")
    
    # æµ‹è¯•ç”¨ä¾‹2: å¸¦å‰ç¼€çš„JSON
    parser.reset()
    print("\næµ‹è¯•2: å¸¦å‰ç¼€çš„JSON")
    messy_json = 'Here is the analysis: {"issues": [{"type": "test"}]}'
    result = parser.add_chunk(messy_json)
    if result:
        print(f"  âœ… è§£ææˆåŠŸ: {result}")
    else:
        print("  âŒ è§£æå¤±è´¥")
    
    # æµ‹è¯•ç”¨ä¾‹3: é”™è¯¯çš„JSON
    parser.reset()
    print("\næµ‹è¯•3: é”™è¯¯çš„JSONå¤„ç†")
    bad_json = '{"issues": [{"type": "test"'  # ä¸å®Œæ•´çš„JSON
    result = parser.add_chunk(bad_json)
    print(f"  ç¼“å†²çŠ¶æ€: {parser.get_buffer_info()}")
    
    # å®ŒæˆJSON
    result = parser.add_chunk('}]}')
    if result:
        print(f"  âœ… æœ€ç»ˆè§£ææˆåŠŸ: {result}")
    else:
        print("  âŒ æœ€ç»ˆè§£æå¤±è´¥")


if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    test_html_conversion()
    test_streaming_json_parser()