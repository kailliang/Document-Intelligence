from __future__ import annotations

import os
import json
from typing import AsyncGenerator, Dict, Any, List

from dotenv import load_dotenv
from openai import AsyncOpenAI

import logging

from app.internal.prompt_enhanced import ENHANCED_PROMPT, FUNCTION_TOOLS

logger = logging.getLogger(__name__)

load_dotenv(override=True)  # å¼ºåˆ¶è¦†ç›–ç¯å¢ƒå˜é‡

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_MODEL = os.getenv("OPENAI_MODEL") or "gpt-4o"


def get_ai_enhanced(
    model: str | None = OPENAI_MODEL,
    api_key: str | None = OPENAI_API_KEY,
) -> AIEnhanced:
    if not api_key or not model:
        raise ValueError("Both API key and model need to be set")
    return AIEnhanced(api_key, model)


class AIEnhanced:
    def __init__(self, api_key: str, model: str):
        self.model = model
        self._client = AsyncOpenAI(api_key=api_key)

    async def review_document_with_functions(self, document: str) -> AsyncGenerator[str | None, None]:
        """
        Review patent document using Function Calling for more precise suggestions.
        
        Arguments:
        document -- Patent document to review
        
        Response:
        Yields JSON with suggestions including originalText and replaceTo fields
        """
        logger.info(f"ğŸ“„ å¼€å§‹å¢å¼ºç‰ˆAIåˆ†æï¼Œæ–‡æ¡£é•¿åº¦: {len(document)}")
        logger.info(f"ğŸ“„ æ–‡æ¡£å†…å®¹é¢„è§ˆ: {document[:200]}...")
        
        # ä½¿ç”¨Function Callingè¿›è¡Œåˆ†æ
        stream = await self._client.chat.completions.create(
            model=self.model,
            temperature=0.1,  # ä½æ¸©åº¦ç¡®ä¿è¾“å‡ºç¨³å®šæ€§å’ŒFunction Callingå¯é æ€§
            messages=[
                {"role": "system", "content": ENHANCED_PROMPT},
                {"role": "user", "content": document},
            ],
            tools=FUNCTION_TOOLS,
            tool_choice="auto",  # è®©AIè‡ªåŠ¨å†³å®šè°ƒç”¨å¤šå°‘æ¬¡å‡½æ•°ï¼Œè€Œä¸æ˜¯å¼ºåˆ¶å•æ¬¡è°ƒç”¨
            stream=True,
        )

        # æ”¶é›†function calls
        function_calls = []
        current_function_calls = {}  # ç”¨å­—å…¸è·Ÿè¸ªå¤šä¸ªå¹¶è¡Œçš„function calls
        
        logger.info("ğŸ”„ å¼€å§‹å¤„ç†AIæµå¼å“åº”...")
        
        async for chunk in stream:
            delta = chunk.choices[0].delta
            
            # è®°å½•æ™®é€šæ–‡æœ¬å†…å®¹ï¼ˆç”¨äºè°ƒè¯•ï¼‰
            if delta.content:
                logger.debug(f"ğŸ“ AIæ–‡æœ¬å“åº”: {delta.content}")
            
            # å¤„ç†tool calls
            if delta.tool_calls:
                logger.info(f"ğŸ”§ æ”¶åˆ°tool call: {delta.tool_calls}")
                for tool_call in delta.tool_calls:
                    call_index = tool_call.index
                    
                    if tool_call.function.name:
                        # æ–°çš„function callå¼€å§‹
                        if call_index in current_function_calls:
                            # å¦‚æœè¿™ä¸ªindexå·²ç»æœ‰function callï¼Œå…ˆä¿å­˜ä¹‹å‰çš„
                            function_calls.append(current_function_calls[call_index])
                        
                        current_function_calls[call_index] = {
                            "name": tool_call.function.name,
                            "arguments": tool_call.function.arguments or ""
                        }
                        logger.info(f"ğŸ†• æ–°çš„function call {call_index}: {tool_call.function.name}")
                        
                    elif call_index in current_function_calls:
                        # ç»§ç»­ç´¯ç§¯è¿™ä¸ªindexçš„arguments
                        current_function_calls[call_index]["arguments"] += tool_call.function.arguments or ""
        
        # æ·»åŠ æ‰€æœ‰å‰©ä½™çš„function calls
        for call_index, func_call in current_function_calls.items():
            function_calls.append(func_call)
        
        logger.info(f"ğŸ“Š æ”¶é›†åˆ° {len(function_calls)} ä¸ªfunction calls")
        for i, call in enumerate(function_calls):
            logger.info(f"ğŸ”§ Function call {i+1}: {call['name']}")
            logger.debug(f"ğŸ”§ Arguments: {call['arguments'][:200]}...")
        
        # å¤„ç†å¹¶ç”Ÿæˆå“åº”
        issues = []
        for func_call in function_calls:
            if func_call["name"] == "create_suggestion":
                try:
                    args = json.loads(func_call["arguments"])
                    logger.info(f"âœ… è§£æfunction argumentsæˆåŠŸ: {args}")
                    
                    # å¤„ç†æ–°æ ¼å¼ï¼šä¸€ä¸ªæ–‡æœ¬æ®µå¯èƒ½æœ‰å¤šä¸ªissues
                    text_issues = args.get("issues", [])
                    
                    # å¦‚æœæ˜¯æ—§æ ¼å¼ï¼ˆå‘åå…¼å®¹ï¼‰
                    if not text_issues and args.get("type"):
                        text_issues = [{
                            "type": args.get("type", ""),
                            "severity": args.get("severity", "medium"),
                            "description": args.get("description", "")
                        }]
                    
                    # åˆ›å»ºä¸€ä¸ªå•ä¸€çš„å»ºè®®æ¡ç›®ï¼ŒåŒ…å«æ‰€æœ‰issues
                    if text_issues:
                        # åˆå¹¶æ‰€æœ‰issuesçš„ç±»å‹å’Œæè¿°
                        types = [issue.get("type", "") for issue in text_issues]
                        descriptions = [issue.get("description", "") for issue in text_issues]
                        severities = [issue.get("severity", "medium") for issue in text_issues]
                        
                        # é€‰æ‹©æœ€é«˜ä¸¥é‡åº¦
                        severity_order = {"high": 3, "medium": 2, "low": 1}
                        max_severity = max(severities, key=lambda x: severity_order.get(x, 2))
                        
                        # åˆ›å»ºå•ä¸€å»ºè®®
                        issue = {
                            "type": " & ".join(types),  # åˆå¹¶æ‰€æœ‰issueç±»å‹
                            "severity": max_severity,
                            "paragraph": args.get("paragraph", 1),
                            "description": " | ".join(descriptions),  # åˆå¹¶æ‰€æœ‰æè¿°
                            "text": args.get("originalText", ""),  # æ˜ å°„å­—æ®µ
                            "suggestion": args.get("replaceTo", ""),  # æ˜ å°„å­—æ®µ
                            "originalText": args.get("originalText", ""),
                            "replaceTo": args.get("replaceTo", ""),
                            "issues": text_issues  # ä¿ç•™è¯¦ç»†çš„issuesæ•°ç»„ä¾›UIä½¿ç”¨
                        }
                        issues.append(issue)
                        logger.info(f"ğŸ“ æ·»åŠ å»ºè®®: {issue['type']} - åŒ…å« {len(text_issues)} ä¸ªé—®é¢˜")
                except json.JSONDecodeError as e:
                    logger.error(f"âŒ JSONè§£æå¤±è´¥: {e}")
                    logger.error(f"âŒ åŸå§‹arguments: {func_call['arguments']}")
                    continue
        
        logger.info(f"âœ¨ æœ€ç»ˆç”Ÿæˆ {len(issues)} ä¸ªå»ºè®®")
        
        # ç”ŸæˆJSONå“åº”
        response = json.dumps({"issues": issues}, ensure_ascii=False)
        logger.info(f"ğŸ“¤ è¿”å›å“åº”: {response[:200]}...")
        yield response

    async def chat_with_user(self, messages: List[Dict[str, str]]) -> AsyncGenerator[str | None, None]:
        """
        èŠå¤©åŠŸèƒ½ï¼Œæ”¯æŒFunction Calling
        
        Arguments:
        messages -- èŠå¤©å†å²æ¶ˆæ¯åˆ—è¡¨
        
        Response:
        æµå¼è¿”å›AIå“åº”
        """
        stream = await self._client.chat.completions.create(
            model=self.model,
            temperature=0.2,  # èŠå¤©æ—¶ç¨é«˜ä¸€ç‚¹çš„æ¸©åº¦ï¼Œä¿æŒä¸€å®šåˆ›é€ æ€§
            messages=messages,
            tools=FUNCTION_TOOLS,
            tool_choice="auto",
            stream=True,
        )

        async for chunk in stream:
            delta = chunk.choices[0].delta
            
            # å¤„ç†æ™®é€šæ–‡æœ¬å“åº”
            if delta.content:
                yield delta.content
            
            # å¤„ç†å·¥å…·è°ƒç”¨
            if delta.tool_calls:
                for tool_call in delta.tool_calls:
                    if tool_call.function.name == "create_diagram":
                        # å¤„ç†å›¾è¡¨ç”Ÿæˆ
                        try:
                            args = json.loads(tool_call.function.arguments)
                            diagram_response = {
                                "type": "diagram",
                                "data": args
                            }
                            yield f"\n```mermaid\n{args.get('mermaid_syntax', '')}\n```\n"
                        except json.JSONDecodeError:
                            continue